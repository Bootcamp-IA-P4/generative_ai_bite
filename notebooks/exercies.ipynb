{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ejercicio 1: Conexión a API de LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Hola! Puedo ayudarte con una variedad de tareas, como responder preguntas, proporcionar información sobre diversos temas, ayudarte a aprender algo nuevo, ofrecer recomendaciones de libros o películas, ayudarte a resolver problemas o darte ideas para proyectos. ¿En qué te gustaría que te ayude hoy?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carga las variables del archivo .env en el entorno\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"OPENROUTER_API_KEY\")  # Obtiene la API key de forma segura\n",
    "API_URL = \"https://openrouter.ai/api/v1/chat/completions\"  # Endpoint de OpenRouter\n",
    "HEADERS = {\"Authorization\": f\"Bearer {API_KEY}\"}  # Cabeceras de autenticación (estándar OAuth 2.0 para API REST)\n",
    "\n",
    "import requests # Biblioteca que permite hacer peticiones HTTP\n",
    "\n",
    "def chat_api(messages): \n",
    "   data = {\n",
    "       \"model\": \"gpt-4o-mini\",  # Modelo a usar (puedes cambiarlo por otros)\n",
    "       \"messages\": messages,    # Array de mensajes de la conversación\n",
    "   }\n",
    "   \n",
    "   # Envía la petición HTTP POST a la API\n",
    "   response = requests.post(API_URL, headers=HEADERS, json=data)\n",
    "   \n",
    "   if response.status_code == 200:  # Si la respuesta es exitosa\n",
    "       return response.json()[\"choices\"][0][\"message\"][\"content\"]  # Extrae solo el texto de respuesta\n",
    "   else:  # Si hay error\n",
    "       return f\"Error {response.status_code}: {response.text}\"\n",
    "\n",
    "# Prueba la función con un mensaje simple\n",
    "print(chat_api([{\"role\": \"user\", \"content\": \"Hola, ¿qué puedes hacer?\"}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **¿Qué hace?**\n",
    "Este ejercicio conecta tu aplicación web a modelos de IA avanzados (GPT-4, Claude, Llama) a través de internet. En lugar de instalar modelos gigantes localmente, envías mensajes a servicios especializados y recibes respuestas inteligentes. Es como tener acceso directo a los mejores cerebros artificiales del mundo desde tu código.\n",
    "\n",
    "### **Conceptos clave**\n",
    "**OpenRouter** es un servicio que te da acceso a más de 200 modelos con una sola API. Puedes cambiar entre GPT-4 (más inteligente), Claude (mejor para textos largos) o Llama (open source) simplemente modificando una línea de código. Las credenciales se guardan de forma segura en un archivo `.env` para proteger tus API keys.\n",
    "\n",
    "### **Ventajas**\n",
    "Obtienes escalabilidad automática, acceso a modelos siempre actualizados, y pagas solo por uso real. Es mucho más eficiente que gestionar modelos locales, especialmente para aplicaciones web que necesitan manejar múltiples usuarios simultáneamente.\n",
    "\n",
    "### **Otras APIs disponibles**\n",
    "También puedes usar **OpenAI** directamente (GPT-4, ChatGPT), **Anthropic** (Claude), **Google Cloud AI** (Gemini), o **Amazon Bedrock**. Cada una tiene sus ventajas específicas en términos de modelos, precios e integración con otros servicios.\n",
    "\n",
    "### **Utilidad práctica**\n",
    "Esta función `chat_api()` es tu base para implementar chatbots, generadores de contenido, asistentes de código y análisis de texto. Con unas pocas líneas, cualquier aplicación web puede tener capacidades conversacionales avanzadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  **Ejercicio 2: Personalización y Contexto Conversacional**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usuario: Explícame qué es una API REST.\n",
      "Asistente: Lo siento, pero solo puedo ayudar con temas relacionados con lámparas de Ikea. Si tienes preguntas sobre lámparas Ikea, estaré encantado de ayudarte.\n",
      "\n",
      "Usuario: ¿Qué tipos de lámparas de Ikea recomendáis para un salón pequeño?\n",
      "Asistente: En un salón pequeño, es importante elegir lámparas que no ocupen mucho espacio y que ofrezcan una buena iluminación. Aquí te recomiendo algunos tipos de lámparas de Ikea que podrían ser adecuadas:\n",
      "\n",
      "1. **Lámparas de pie**: Son ideales porque no ocupan espacio en la mesa y pueden proporcionar una buena iluminación general. Modelos como la lámpara de pie **HEKTAR** ofrecen un diseño compacto y moderno.\n",
      "\n",
      "2. **Lámparas de mesa**: Opta por modelos pequeños y ligeros como la **RANARP** o la **FADO**, que pueden colocarse sobre mesas auxiliares o estanterías sin abrumar el espacio.\n",
      "\n",
      "3. **Apliques de pared**: Si quieres ahorrar espacio en el suelo y obtener una buena distribución de la luz, considera apliques como el modelo **VÄGGIS**. \n",
      "\n",
      "4. **Lámparas de techo**: Las lámparas empotradas o las de tipo **huevo** pueden ser opciones efectivas si el espacio es restringido. Modelos como **HEKTAR** o **FADO** también están disponibles para instalaciones de techo.\n",
      "\n",
      "5. **Lámparas colgantes**: Considera usar una lámpara colgante ligera que no cuelgue demasiado bajo, como la **RANARP**, que puede agregar carácter sin ocupar demasiado espacio.\n",
      "\n",
      "Recuerda que la elección depende de tu estilo y la atmósfera que desees crear en el salón. ¡Espero que encuentres la lámpara perfecta para tu espacio!\n",
      "\n",
      "Usuario: ¿Qué me puedes decir sobre los sofás de Ikea?\n",
      "Asistente: Lo siento, pero solo puedo ayudar con temas relacionados con lámparas de Ikea. Si tienes alguna pregunta sobre lámparas, estaré encantado de asistirte.\n"
     ]
    }
   ],
   "source": [
    "def chat_api(messages, model=\"gpt-4o-mini\"):\n",
    "   \"\"\"\n",
    "   Función principal para comunicarse con la API de LLM\n",
    "   \n",
    "   \"\"\"\n",
    "   \n",
    "   # Preparar los datos que enviaremos a la API\n",
    "   data = {\n",
    "       \"model\": model,        # Especifica qué modelo queremos usar\n",
    "       \"messages\": messages,  # La conversación completa (system + user + assistant)\n",
    "   }\n",
    "   \n",
    "   # Realizar petición POST a la API de OpenRouter\n",
    "   response = requests.post(\n",
    "       API_URL,           # URL del endpoint de OpenRouter\n",
    "       headers=HEADERS,   # Cabeceras con autenticación (API key)\n",
    "       json=data          # Datos en formato JSON\n",
    "   )\n",
    "   \n",
    "   # Verificar si la petición fue exitosa\n",
    "   if response.status_code == 200:\n",
    "       # Si todo salió bien, extraer solo el texto de la respuesta\n",
    "       return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "   else:\n",
    "       # Si hubo error, devolver información del problema\n",
    "       return f\"Error {response.status_code}: {response.text}\"\n",
    "\n",
    "# Contexto inicial: asistente experto en lámparas Ikea\n",
    "system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": (\n",
    "        \"Eres un asistente experto que solo puede responder preguntas sobre lámparas de Ikea. \"\n",
    "        \"No sabes nada sobre programación ni otros temas, y si te preguntan sobre algo fuera de lámparas Ikea, \"\n",
    "        \"debes responder amablemente que solo puedes ayudar con temas relacionados con lámparas Ikea.\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# Inicializamos la conversación con el system message\n",
    "messages = [system_message]\n",
    "\n",
    "# Pregunta 1: fuera del ámbito (programación)\n",
    "messages.append({\"role\": \"user\", \"content\": \"Explícame qué es una API REST.\"})\n",
    "respuesta1 = chat_api(messages)\n",
    "print(\"Usuario: Explícame qué es una API REST.\")\n",
    "print(\"Asistente:\", respuesta1)\n",
    "\n",
    "# Añadimos la respuesta a la conversación para mantener contexto (memoria conversacional)\n",
    "messages.append({\"role\": \"assistant\", \"content\": respuesta1})\n",
    "\n",
    "# Pregunta 2: dentro del ámbito (lámparas Ikea)\n",
    "messages.append({\"role\": \"user\", \"content\": \"¿Qué tipos de lámparas de Ikea recomendáis para un salón pequeño?\"})\n",
    "respuesta2 = chat_api(messages)\n",
    "print(\"\\nUsuario: ¿Qué tipos de lámparas de Ikea recomendáis para un salón pequeño?\")\n",
    "print(\"Asistente:\", respuesta2)\n",
    "\n",
    "# Añadimos la respuesta a la conversación\n",
    "messages.append({\"role\": \"assistant\", \"content\": respuesta2})\n",
    "\n",
    "# Pregunta 3: fuera del ámbito otra vez (sofás Ikea)\n",
    "messages.append({\"role\": \"user\", \"content\": \"¿Qué me puedes decir sobre los sofás de Ikea?\"})\n",
    "respuesta3 = chat_api(messages)\n",
    "print(\"\\nUsuario: ¿Qué me puedes decir sobre los sofás de Ikea?\")\n",
    "print(\"Asistente:\", respuesta3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **¿Qué hace?**\n",
    "\n",
    "Este ejercicio demuestra cómo crear **asistentes especializados** que mantienen una personalidad específica y recordar el contexto de conversaciones largas. El asistente se comporta como un experto en lámparas de IKEA que rechaza amablemente preguntas fuera de su especialidad, mostrando cómo controlar el comportamiento de la IA mediante prompts estructurados.\n",
    "\n",
    "### **Conceptos clave**\n",
    "\n",
    "**System Message** es la instrucción fundamental que define la personalidad y límites del asistente. Actúa como el \"ADN\" del chatbot, estableciendo qué puede y no puede hacer. En este caso, creamos un experto que solo sabe de lámparas IKEA y rechaza educadamente otros temas, incluso relacionados como sofás de la misma marca.\n",
    "\n",
    "**Contexto conversacional** se mantiene añadiendo cada intercambio (usuario y asistente) a la lista `messages`. Esto permite que el modelo recuerde toda la conversación anterior y mantenga coherencia, como haría un humano. Cada nueva pregunta se procesa considerando todo el historial previo.\n",
    "\n",
    "**Especialización controlada** demuestra cómo un modelo general como GPT-4 puede comportarse como un experto muy específico. No necesitas entrenar un modelo desde cero; simplemente defines su comportamiento mediante instrucciones claras en el system message.\n",
    "\n",
    "### **Ventajas prácticas**\n",
    "\n",
    "Esta técnica permite crear **múltiples asistentes especializados** usando el mismo modelo base: un experto en programación Python, un consultor de marketing digital, o un tutor de matemáticas. Cada uno mantiene su personalidad y conocimientos específicos, rechazando preguntas fuera de su dominio para evitar respuestas incorrectas o confusas.\n",
    "\n",
    "**Para aplicaciones web**, esto significa que puedes tener diferentes secciones de tu sitio con asistentes especializados: soporte técnico, ventas, educación, cada uno optimizado para su función específica sin interferencias.\n",
    "\n",
    "### **Utilidad real**\n",
    "\n",
    "Este patrón es fundamental para **chatbots de empresa** que necesitan mantenerse dentro de límites específicos, **asistentes educativos** que se enfocan en materias concretas, y **sistemas de soporte** que dirigen usuarios hacia los canales correctos cuando no pueden ayudar directamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ejercicio 3: IA Multimodal - Imagen + Texto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen: https://cdn.sklum.com/es/1160461/lampara-de-pie-francis.jpg\n",
      "Descripción detallada: Esta lámpara de pie presenta un diseño moderno y elegante, ideal para complementar diversos estilos de decoración.\n",
      "\n",
      "### Estilo\n",
      "- **Estilo:** Contemporáneo, con toques minimalistas. Su forma limpia y sus líneas rectas la hacen adecuada para espacios modernos y sofisticados.\n",
      "- **Detalles:** La combinación de los acabados mate en negro y los acentos dorados le da un toque de sofisticación y lujo.\n",
      "\n",
      "### Materiales\n",
      "- **Pantalla:** Metal, con un acabado mate que permite una distribución uniforme de la luz.\n",
      "- **Estructura:** También de metal, lo que asegura durabilidad y estabilidad.\n",
      "- **Base:** Sólida y redonda, capaz de soportar el peso de la lámpara para evitar que se vuelque.\n",
      "\n",
      "### Tipo de Luz\n",
      "- **Iluminación:** Generalmente esta lámpara usa bombillas LED, lo que proporciona una luz cálida y acogedora, ideal para la lectura o momentos de relajación.\n",
      "- **Direccionalidad:** Gracias a su diseño ajustable, permite dirigir la luz donde más se necesite.\n",
      "\n",
      "### Tamaño Aproximado\n",
      "- **Dimensiones:** Al no tener una medida exacta, se puede estimar que la lámpara tiene una altura de aproximadamente 150-170 cm y un diámetro de base de unos 30 cm.\n",
      "\n",
      "### Recomendaciones de Uso y Decoración\n",
      "1. **Ubicación:** Ideal para colocar junto a un sofá o una silla de lectura en salones o espacios de entretenimiento. También puede funcionar en un rincón de una habitación para crear un área de lectura acogedora.\n",
      "2. **Complementos:** Acompañarla con almohadones en tonos neutros o con estampados que resalten el acabado dorado puede crear armonía.\n",
      "3. **Ambiente:** Colocar esta lámpara en un entorno donde los materiales metálicos y tonos neutros predominen ayudará a realzar su diseño.\n",
      "4. **Acentos:** Utilizarla junto a otros elementos de decoración metálicos, como marcos dorados o mesas con acabados similares, para crear un look cohesivo.\n",
      "\n",
      "En resumen, esta lámpara no solo es funcional, sino que también actúa como una pieza decorativa que puede elevar el estilo de cualquier habitación.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import base64\n",
    "\n",
    "def chat_api_with_model(messages, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"Versión de chat_api que acepta imagenes\"\"\"\n",
    "    data = {\n",
    "        \"model\": model,  \n",
    "        \"messages\": messages,\n",
    "    }\n",
    "    response = requests.post(API_URL, headers=HEADERS, json=data)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        return f\"Error {response.status_code}: {response.text}\"\n",
    "\n",
    "def image_to_base64(image_url):\n",
    "    \"\"\"Convierte imagen de URL a base64 para enviar a la API\"\"\"\n",
    "    response = requests.get(image_url)  # Descarga los datos binarios de la imagen a través de una petición HTTP\n",
    "    image_data = base64.b64encode(response.content).decode('utf-8')  # Codifica en base64 (convierte los bytes a una cadena de texto)\n",
    "    return image_data\n",
    "\n",
    "def analyze_lamp_with_api(image_url):\n",
    "    \"\"\"Analiza lámpara usando API multimodal especializada\"\"\"\n",
    "    \n",
    "    # Convertir imagen a base64\n",
    "    image_base64 = image_to_base64(image_url)\n",
    "    \n",
    "    # Mensaje especializado para análisis de lámparas\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Eres un experto en iluminación e interiorismo especializado en lámparas. Analiza cada lámpara describiendo detalladamente su estilo, materiales, tipo de iluminación, y da recomendaciones específicas de uso y decoración. En caso de no identificar una lámpara, especifica que no es una lámpara Ikea o que no puedes identificarla.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": [  # Contenido multimodal: texto + imagen\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Describe detalladamente esta lámpara: estilo, materiales, tipo de luz, tamaño aproximado, y dame recomendaciones específicas de dónde y cómo usarla en decoración.\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{image_base64}\"  # Imagen codificada. Indicación: lo que viene a continuación es una cadena de texto que representa la imagen en base64\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Usar modelo con capacidades de visión\n",
    "    return chat_api_with_model(messages, model=\"gpt-4o-mini\")\n",
    "\n",
    "# URL de imagen\n",
    "image_url = \"https://cdn.sklum.com/es/1160461/lampara-de-pie-francis.jpg\"\n",
    "\n",
    "#  Doraemon - \"https://upload.wikimedia.org/wikipedia/en/b/bd/Doraemon_character.png\"\n",
    "# Lampara alargada - \"https://img.kwcdn.com/product/fancy/377ce740-e4ca-4b70-80d6-631545b01c20.jpg\"\n",
    "# Lámpara de pie  - \"https://cdn.sklum.com/es/1160461/lampara-de-pie-francis.jpg\"\n",
    "\n",
    "# Analizar lámpara y obtener descripción detallada\n",
    "response = analyze_lamp_with_api(image_url)\n",
    "\n",
    "print(\"Imagen:\", image_url)\n",
    "print(\"Descripción detallada:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **¿Qué hace?**\n",
    "\n",
    "Este ejercicio demuestra cómo crear un **asistente visual** que puede analizar imágenes y dar recomendaciones expertas sobre ellas. Usa modelos multimodales como **GPT-4o-mini** que procesan imagen y texto simultáneamente, eliminando la necesidad de modelos locales complejos y problemas de compatibilidad.\n",
    "\n",
    "### **Conceptos clave**\n",
    "\n",
    "**Multimodalidad nativa** significa que el modelo ve directamente la imagen junto con las instrucciones de texto, no necesita una descripción intermedia. **GPT-4o-mini** recibe la imagen codificada en base64 y puede analizarla visualmente mientras considera el contexto y especialidad definidos en el system message.\n",
    "\n",
    "**Codificación base64** convierte cualquier imagen en una cadena de texto que puede transmitirse a través de APIs web. Es el método estándar para enviar imágenes a servicios de IA sin subirlas a servidores externos, manteniendo privacidad y simplicidad.\n",
    "\n",
    "**Estructura de mensaje multimodal** combina diferentes tipos de contenido en un solo mensaje: texto con instrucciones específicas e imagen para análisis. El modelo procesa ambos tipos de información de forma integrada para generar respuestas contextualizadas.\n",
    "\n",
    "### **Ventajas prácticas**\n",
    "\n",
    "Esta aproximación es **más robusta y mantenible** que usar modelos locales porque evita problemas de dependencias, versiones de PyTorch, y compatibilidad de hardware. También es **más precisa** porque el modelo analiza directamente la imagen sin perder detalles en traducciones intermedias.\n",
    "\n",
    "**Para aplicaciones web**, significa implementar funcionalidades como \"sube una foto y recibe análisis experto\" con código simple y confiable, sin preocupaciones técnicas sobre gestión de modelos de visión artificial localmente.\n",
    "\n",
    "### **Utilidad real**\n",
    "\n",
    "Este patrón permite crear **asistentes visuales profesionales** para e-commerce (análisis de productos), consultoría de estilo (evaluación de outfits o espacios), educación (explicación de diagramas), y diagnóstico básico (análisis de imágenes médicas) con máxima simplicidad técnica y resultados de calidad profesional."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
